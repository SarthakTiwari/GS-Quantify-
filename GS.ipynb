{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRzi0jiGBVaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmqK02JpFsHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data = [line.strip() for line in open(\"drive/My Drive/GS/train_set.txt\", \"r\").readlines()]\n",
        "pub_test = [line.strip() for line in open(\"drive/My Drive/GS/public_test_set.txt\", \"r\").readlines()]\n",
        "pri_test = [line.strip() for line in open(\"drive/My Drive/GS/private_test_set.txt\", \"r\").readlines()]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE3Ky9JDyTuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data1=[[re.findall(r\"\\w+(?=~)\",i)[0],i.split(\"] \")[-1]] for i in data]\n",
        "pub1=[[re.findall(r\"\\w+(?=~)\",i)[0],i.split(\"] \")[-1]] for i in pub_test]\n",
        "pri1=[[re.findall(r\"\\w+(?=~)\",i)[0],i.split(\"] \")[-1]] for i in pri_test]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zkovcdeYY4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleaning(data):\n",
        "  d=[]\n",
        "  for i in data:\n",
        "    if i[1][0]=='L':\n",
        "      pass\n",
        "    else:\n",
        "      a=re.sub(r\"/.*(?<=/)\\S+\",\"\",i[1])\n",
        "      a=re.sub(r\"\\d*\\.?\\d*\",\"\",a)\n",
        "      d.append([i[0],a])\n",
        "  d=pd.DataFrame(d)\n",
        "   \n",
        "  return d\n",
        "data2=cleaning(data1)\n",
        "pub2=cleaning(pub1)\n",
        "pri2=cleaning(pri1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0Cit8Sn7UoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import LancasterStemmer\n",
        "\n",
        "def to_lowercase(words):\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = word.lower()\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def remove_punctuation(words):\n",
        "   \n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
        "        if new_word != '':\n",
        "            new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "\n",
        "def stem_words(words):\n",
        "    \n",
        "    stemmer = LancasterStemmer()\n",
        "    stems = []\n",
        "    for word in words:\n",
        "        stem = stemmer.stem(word)\n",
        "        stems.append(stem)\n",
        "    return stems\n",
        "  \n",
        "def lemmatize_verbs(words):\n",
        "    \n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmas = []\n",
        "    for word in words:\n",
        "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "        lemmas.append(lemma)\n",
        "    return lemmas\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def normalize(words):\n",
        "    words = to_lowercase(words)\n",
        "    words = remove_punctuation(words)\n",
        "    words = stem_words(words)\n",
        "\n",
        "    return words\n",
        "\n",
        "\n",
        "data2[1]=normalize(data2[1])\n",
        "pub2[1]=normalize(pub2[1])\n",
        "pri2[1]=normalize(pri2[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkFlkfgD99_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "data3=data2[1].drop_duplicates()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8L94M17N4Az",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data3=list(data3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfYGIyk2Q0WP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "cef37505-06c0-43ec-b344-9fb1d1286759"
      },
      "source": [
        "data3"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['http exception thrown no entry found for any event',\n",
              " 'creating event networkvifplugged for instance',\n",
              " 'delete  status  len  time ',\n",
              " 'get  status  len  time ',\n",
              " 'total disk upperlimit not defined defaulting to unlimited',\n",
              " 'http exception thrown no instances found for any event',\n",
              " 'base or swap file too young to remove ',\n",
              " 'active base files ',\n",
              " 'total usable memory gb total allocated memory gb',\n",
              " 'vm paused lifecycle event',\n",
              " 'vm resumed lifecycle event',\n",
              " 'swap instance creation successfully',\n",
              " 'total usable vgpus  total allocated vgpus ',\n",
              " 'instance spawned correctly',\n",
              " 'vm stopped lifecycle event',\n",
              " 'removable base files ',\n",
              " 'unknown base file ',\n",
              " 'total usable vcpus  total allocated vcpus ',\n",
              " 'instance destroyed successfully',\n",
              " 'vm started lifecycle event',\n",
              " 'removing base or swap file ',\n",
              " 'total usable disk gb total allocated disk gb',\n",
              " 'deleting instance files ',\n",
              " 'post  status  len  time ',\n",
              " 'vcpu limit not specified default to unlimited',\n",
              " 'total memory limit not specified defaulting to unlimited',\n",
              " 'vm limit not defined defaulting to max',\n",
              " 'takes  seconds to deallocate network for instance',\n",
              " 'took  seconds to spawn the instance on the hypervisor',\n",
              " 'took  seconds to destroy the instance on the hypervisor',\n",
              " 'takes  seconds to build the instance']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn2DF3uzAbib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWviCZofA8AQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf = tfidf_vectorizer.fit_transform(data3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdqjSReUD8GI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "kmeans = KMeans(n_clusters=6).fit(tfidf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlB9oklSed1h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "62ccd22b-cc75-48e5-cb99-b26fbce04fa7"
      },
      "source": [
        "kmeans.predict(tfidf_vectorizer.transform(pub2[1]))"
      ],
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 4, 5, 0, 5, 4, 5, 1, 1, 5, 5, 1, 1, 3, 3, 5, 1, 5, 4, 2, 1,\n",
              "       3, 5, 3, 3, 5, 3, 3, 5, 4, 2, 3, 5, 0, 4, 1, 2, 0, 1, 4, 3, 5, 1,\n",
              "       5, 3, 0, 4, 5, 1, 0, 5, 5, 5, 3, 5, 5, 4, 0, 2, 5, 2, 3, 5, 5, 1,\n",
              "       4, 2, 5, 1, 3, 1, 5, 5, 3, 2, 1, 5, 0, 2, 3, 3, 1, 5, 1, 4, 4, 0,\n",
              "       2, 5, 5, 1, 1, 3, 5, 1, 1, 1, 1, 3, 1, 1, 0, 5, 0, 1, 5, 5, 1, 1,\n",
              "       0, 2, 3, 1, 2, 1, 2, 5, 5, 1, 0, 1, 2, 5, 5, 0, 0, 1, 1, 4, 0, 5,\n",
              "       5, 2, 5, 3, 5, 1, 1, 3, 5, 1, 1, 3, 5, 3, 1, 5, 1, 5, 3, 5, 5, 4,\n",
              "       0, 2, 5, 2, 1, 4, 2, 3, 5, 4, 1, 3, 2, 3, 3, 0, 2, 2, 5, 3, 5, 5,\n",
              "       3, 3, 3, 4, 5, 0, 5, 5, 3, 5, 0, 5, 1, 3, 0, 0, 3, 1, 0, 2, 3, 3,\n",
              "       0, 2, 3, 1, 5, 3, 2, 5, 2, 1, 0, 3, 1, 3, 1, 5, 3, 4, 3, 0, 1, 5,\n",
              "       5, 4, 5, 0, 1, 1, 5, 0, 4, 3, 1, 4, 5, 0, 1, 3, 4, 0, 1, 1, 5, 4,\n",
              "       1, 2, 1, 5, 2, 1, 1, 3, 2, 3, 5, 0, 5, 5, 0, 0, 0, 3, 5, 5, 1, 5,\n",
              "       3, 5, 3, 3, 5, 1, 3, 3, 3, 1, 1, 2, 3, 3, 3, 5, 0, 1, 0, 1, 1, 4,\n",
              "       4, 5, 0, 2, 5, 4, 2, 5, 2, 0, 1, 3, 3, 3, 1, 3, 1, 1, 5, 1, 2, 0,\n",
              "       0, 5, 1, 5, 4, 0, 1, 0, 2, 5, 0, 3, 1, 0, 1, 0, 1, 4, 1, 0, 4, 3,\n",
              "       1, 5, 1, 5, 1, 5, 3, 0, 4, 5, 5, 2, 4, 1, 3, 2, 5, 2, 3, 0, 1, 5,\n",
              "       3, 3, 1, 1, 1, 0, 1, 5, 1, 0, 1, 1, 2, 3, 1, 5, 4, 5, 4, 1, 2, 1,\n",
              "       5, 0, 0, 5, 1, 1, 1, 4, 5, 4, 1, 5, 3, 5, 3, 0, 1, 5, 3, 3, 5, 0,\n",
              "       5, 0, 3, 1, 3, 5, 3, 5, 1, 0, 1, 0, 1, 4, 3, 1, 2, 3, 5, 3, 1, 1,\n",
              "       0, 2, 3, 5, 4, 5, 5, 1, 3, 3, 0, 4, 3, 0, 1, 1, 5, 5, 0, 5, 3, 5,\n",
              "       2, 0, 5, 3, 5, 5, 4, 3, 5, 3, 5, 0, 1, 5, 5, 5, 1, 2, 1, 5, 1, 1,\n",
              "       3, 1, 0, 3, 0, 0, 0, 1, 5, 4, 2, 3, 1, 1, 0, 5, 1, 2, 1, 5, 1, 1,\n",
              "       3, 5, 5, 0, 2, 3, 2, 5, 5, 1, 3, 2, 3, 3, 4, 0, 5, 1, 1, 0, 4, 1,\n",
              "       3, 4, 0, 1, 1, 5, 3, 0, 1, 0, 5, 5, 0, 0, 0, 1, 1, 5, 3, 0, 5, 4,\n",
              "       0, 1, 1, 2, 1, 5, 1, 1, 0, 0, 0, 2, 3, 1, 3, 2, 5, 0, 5, 1, 3, 0,\n",
              "       2, 1, 1, 0, 0, 5, 3, 1, 3, 2, 5, 2, 5, 1, 5, 5, 0, 5, 3, 1, 5, 2,\n",
              "       3, 3, 1, 5, 3, 0, 0, 0, 2, 1, 1, 0, 0, 1, 4, 1, 3, 1, 1, 5, 0, 3,\n",
              "       0, 0, 5, 0, 4, 5, 2, 0, 0, 5, 2, 3, 0, 3, 5, 5, 5, 0, 4, 1, 4, 1,\n",
              "       5, 4, 5, 3, 0, 5, 5, 3, 0, 2, 4, 1, 3, 5, 5, 4, 5, 5, 0, 0, 3, 1,\n",
              "       2, 1, 1, 3, 0, 0, 5, 1, 5, 5, 5, 3, 5, 4, 3, 3, 0, 5, 0, 1, 3, 0,\n",
              "       1, 3, 4, 5, 1, 5, 1, 0, 5, 1, 1, 1, 0, 3, 5, 5, 5, 5, 4, 4, 0, 3,\n",
              "       3, 1, 5, 3, 0, 3, 0, 1, 3], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 289
        }
      ]
    }
  ]
}